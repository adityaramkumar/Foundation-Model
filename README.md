# Foundation-Model
Building an (extremely basic) foundation model from scratch

## Architecture
I plan to build and train a transformer for this. I will need word embeddings, positional encodings, a self attention layer, and residual connections.

## Training
This model will use the Harry Potter book series for training. I plan to use 2 unsupervised techniques for training: Masked Language Modelling (MLM) and Next Sequence Prediction (NSP). 
